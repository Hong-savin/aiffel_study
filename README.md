# FUND 01~03

---

## 1. 다양한 전처리 기법
### 1-1. 결측치:
	- **isnull()**: null 값을 찾아줌
	- **any(axis=1)**은 열 별로 하나라도 null 값이 있으면...
	- **dropna()**: 결측치를 삭제해 주는 메서드
		- subset 옵션으로 특정 컬럼들을 선택
		- inplace 옵션으로 해당 df 내부에 바로 적용
	- **수치형 데이터 보완 방법**: 평균, 중앙값 -> 결측치가 많은 경우, 모두 같은 값으로 대체하면 데이터의 분산이 실제보다 작아지는 문제 발생, 시계열 특성 데이터의 경우 앞뒤 데이터를 통해 결측치 대체 가능

### 1-2. 중복된 데이터:
	- **duplicated()**: 중복여부를 불리언 값으로 변환
	- **drop_duplicates**: 중복 데이터 삭제, inplace=True를 통해 메서드 실행 후 제거된 결과가 원본 df에 반영, subset(컬럼), keep(last등)

### 1-3. 이상치:
	- **이상치**: 대부분 값의 범위애서 벗어나 극단적으로 크거나 작은 값 의미
	- **IQR**: 제3사분위수에서 제1시분위수를 뺀 값(Q3-Q1)으로, 데이터의 중간 50%의 범위. 이상치는 Q1-1.5*IQR보다 작거나 Q3+1.5*IQR보다 큰 데이터를 의미.
	- **z-score**: 특정 데이터값이 평균으로부터 얼마나 떨어져있나를 표준편차 단위로 확인. (데이터 값-데이터 평균)/(데이터 표준 편차). 절대값 z가 크면 데이터 값이 평균에서 멀리 떨어져있고, 이상치일 가능성이 높다. 

### 1-4. 정규화:
	- **표준화**: 데이터의 평균은 0, 분산은 1로 변환. 표준화는 보통 평균이 0이고 표준편차가 1일 때 사용. 데이터가 가우시안 분포를 따를 경우 유용하게 사용할 수 있다. (데이터 값-데이터 평균)/(데이터 표준 편차)
	- **Min-Max Scaling**: 데이터의 최솟값은 0, 최댓값은 1로 변환. 피처의 범위가 다를 때 주로 사용하며 확률 분포를 모를 때 유용하다. (X-Xmin)/(Xmax-Xmin)

### 1-5. 원-핫 인코딩:
	-**원-핫 인코딩**: 카테고리별 이진 특정을 만들어 해당하는 특성만 1, 나머지는 0으로 만드는 방법. [0, 1, 0, 0] 등의 벡터 형식으로 변환된다.
	- **get_dummies**: pandas의 get_dummies 함수를 통해 쉽게 원-핫 인코딩을 할 수 있다.

### 1-6. 구간화:
	- **cut**: bins를 통해 구간을 정하여 수치형 데이터를 범주형 데이터로 변환한다.
	- **qcut**: q값을 설정하여 데이터의 분포를 비슷한 크기의 q개의 그룹으로 나누어주어 수치형 데이터를 범주형 데이터로 변환한다.

---

## 2. 데이터를 한눈에 시각화
### barplot, violinplot, catplot, scatterplot, lineplot...

### 히스토그램
	- **히스토그램**: 도수분포표를 그래프로 나타낸 것
	- 가로축: 변수의 구간(bin), 세로축: 빈도수(frequency)

### Heatmap
	- **히트맵**: 방대한 양의 데이터와 현상을 수치에 따른 색상으로 나타내는 것
	- 히트맵을 그리기 전에 데이터를 pivot 해야 하는 경우가 있다. pivot이란 어떤 축, 점을 기준으로 바꾼다는 뜻이다.

---

##3. 모델 성능 평가

### 3-1. Loss와 Metric:
	- **Loss**: 모델 학습 시 train data를 바탕으로 계산되어, 모델의 파라미터 업데이트에 활용되는 함수
	- **Metric**: 모델 학습 종료 후 test data를 바탕으로 계산되어, 학습된 모델의 성능을 평가하는데 활용되는 함수
	- **Accuracy**: 분류모델의 성능을 평가하는 데는 Accuracy가 더 우월한 Metric이다. 회귀모델일 경우 RMSE가 Loss와 Metric 양쪽으로 효과정으로 사용될 수도 있다.


### 3-2. Confusion Matrix와 Precision/Recall
	-**Confusion Matrix**: TP(모델이 양성을 양성으로 맞힘), TN(모델이 음성을 음성으로 맞힘), FP(모델이 음성을 양성으로 잘못 예측), FN(모델이 양성을 음성으로 잘못 예측)
	- **Accuracy**: (TP + TN) / (TP + TN + FP + FN)
	- **Precision**: TP / (TP +FP), 모델이 판단한 양성만 관심있음 -> 정밀도가 높다는 건 FP가 낮다는 것
	- **Recall**: TP / (TP + FN), 실제 양성에만 관심이 있음 -> 재현율이 높다는 건 FN이 낮다는 것
	- **F-score**: Precision과 Recall을 결합하여 모델을 평가하는 지표, Recall을 중요시한다면 베타값을 크게 하는 것이 좋다.

### 3-3. Threshold의 변화에 따른 모델 성능
	- Threshold의 변화에 따른 성능 평가 방법으로 PR(Precision and Recall) curve와 ROC curve를 활용할 수 있음

### 3-4. Precision-Recall curve
	- PR 커브는 Recall을 x축, Precision을 y축에 놓고 기준선(Threshold) 변화에 따른 두 값의 변화를 그래프로 그린 것
	- AUC 커브는 Threshold 값에 무관하게 모델의 전체적인 성능을 평가하는 방법으로, PR 커브의 아래 면적을 계산하는 방법.

### 3-5. ROC curve
	- ROC는 Confusion Matrix 수치를 활영해, 분류기의 분류 능력을 그래프로 표현하는 방법
	- 분류가의 Threshold 값의 변화에 따라 Confusion Matrix에 생기는 변화로 인해 그려지는 것
	- ROC AUC의 값이 클수록 모델 성능이 우수하며, AUC는 최대 1까지 도달 가능.
